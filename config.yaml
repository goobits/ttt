# Goobits TTT Default Configuration
# This file contains all default configuration values for the AI library
# User configuration can override these values via ~/.config/ttt/config.yaml

# Model configuration
models:
  default: "openrouter/google/gemini-flash-1.5"
  # Model aliases - these use OpenRouter by default but users can override
  # Users can also use direct provider paths if they have API keys:
  # ttt config set alias.myclaude anthropic/claude-3-sonnet-20240229
  aliases:
    fast: "openrouter/openai/gpt-3.5-turbo"
    best: "openrouter/openai/gpt-4"
    coding: "openrouter/anthropic/claude-3-sonnet-20240229"
    local: "llama2"
    claude: "openrouter/anthropic/claude-3-sonnet-20240229"
    gpt4: "openrouter/openai/gpt-4"
    gpt3: "openrouter/openai/gpt-3.5-turbo"
    gemini: "openrouter/google/gemini-pro"
    mixtral: "openrouter/mistralai/mixtral-8x7b-instruct"
    flash: "openrouter/google/gemini-2.5-flash"

  # Model registry definitions
  available:
    # OpenAI models
    gpt-4:
      provider: "openai"
      provider_name: "gpt-4"
      aliases: ["best", "quality"]
      speed: "slow"
      quality: "high"
      capabilities: ["text", "reasoning"]
      context_length: 8192

    gpt-3.5-turbo:
      provider: "openai"
      provider_name: "gpt-3.5-turbo"
      aliases: ["fast", "cheap"]
      speed: "fast"
      quality: "medium"
      capabilities: ["text", "chat"]
      context_length: 4096

    gpt-4-vision-preview:
      provider: "openai"
      provider_name: "gpt-4-vision-preview"
      aliases: ["vision", "gpt-vision"]
      speed: "slow"
      quality: "high"
      capabilities: ["text", "reasoning", "vision"]
      context_length: 128000

    # Anthropic models
    claude-3-opus:
      provider: "anthropic"
      provider_name: "claude-3-opus-20240229"
      aliases: ["claude-best", "opus"]
      speed: "slow"
      quality: "high"
      capabilities: ["text", "reasoning", "code", "vision"]
      context_length: 200000

    claude-3-sonnet:
      provider: "anthropic"
      provider_name: "claude-3-sonnet-20240229"
      aliases: ["coding", "analysis", "claude"]
      speed: "medium"
      quality: "high"
      capabilities: ["text", "reasoning", "code"]
      context_length: 200000

    claude-3-haiku:
      provider: "anthropic"
      provider_name: "claude-3-haiku-20240307"
      aliases: ["claude-fast", "haiku"]
      speed: "fast"
      quality: "medium"
      capabilities: ["text", "chat"]
      context_length: 200000

    # Google models
    gemini-pro:
      provider: "google"
      provider_name: "gemini-pro"
      aliases: ["gemini", "google"]
      speed: "medium"
      quality: "high"
      capabilities: ["text", "reasoning"]
      context_length: 30720

    gemini-pro-vision:
      provider: "google"
      provider_name: "gemini-pro-vision"
      aliases: ["gemini-vision"]
      speed: "medium"
      quality: "high"
      capabilities: ["text", "reasoning", "vision"]
      context_length: 30720

    # Local models (Ollama)
    llama2:
      provider: "local"
      provider_name: "llama2"
      aliases: ["local", "private"]
      speed: "medium"
      quality: "medium"
      capabilities: ["text", "chat"]
      context_length: 4096

    mistral:
      provider: "local"
      provider_name: "mistral"
      aliases: ["mistral-local"]
      speed: "fast"
      quality: "medium"
      capabilities: ["text", "chat"]
      context_length: 8192

    codellama:
      provider: "local"
      provider_name: "codellama"
      aliases: ["local-code"]
      speed: "medium"
      quality: "medium"
      capabilities: ["code", "text"]
      context_length: 4096

# Backend configuration
backends:
  default: "cloud"

  cloud:
    timeout: 30
    max_retries: 3
    retry_delay: 1.0
    default_models:
      openai: "gpt-3.5-turbo"
      anthropic: "claude-3-sonnet-20240229"
      google: "gemini-pro"
      openrouter: "openrouter/google/gemini-flash-1.5"
    provider_order: ["openai", "anthropic", "google"]

  local:
    base_url: "http://localhost:11434"  # matches constants.urls.ollama_default
    timeout: 60
    default_model: "llama2"

  # Fallback configuration
  enable_fallbacks: true
  fallback_order: ["cloud", "local"]

# Tool configuration
tools:
  max_file_size: 10485760  # 10MB in bytes (matches constants.file_sizes.max_file_size)
  code_execution_timeout: 30  # matches constants.tool_bounds.default_code_timeout
  web_request_timeout: 10     # matches constants.tool_bounds.default_web_timeout
  math_max_iterations: 1000   # matches constants.tool_bounds.math_max_iterations

  # Tool retry configuration
  retry:
    max_attempts: 3
    base_delay: 1.0
    max_delay: 60.0
    rate_limit_min_delay: 5.0

  # Tool timeout bounds
  timeout_bounds:
    min: 1
    max: 30

  # Tool executor defaults
  executor:
    max_retries: 3
    timeout_seconds: 30.0

# Chat configuration
chat:
  default_system_prompt: null
  max_history_length: 100
  auto_save: true

  # Chat interface messages
  commands:
    help_message: "Type /exit to quit, /save <filename> to save session, /clear to clear history"
    available_commands: ["/exit", "/quit", "/save", "/clear", "/help"]

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# File paths configuration
paths:
  # Config file search locations (in order of precedence)
  config_search:
    - "./ai.yaml"
    - "./ai.yml"
    - "./.ai.yaml"
    - "./.ai.yml"
    - "~/.config/ttt/config.yaml"
    - "~/.config/ttt/config.yml"
    - "~/.ai.yaml"
    - "~/.ai.yml"

  # Default save location for user config
  default_config_save: "~/.config/ttt/config.yaml"

# Environment variable mappings
env_mappings:
  openai_api_key: "OPENAI_API_KEY"
  anthropic_api_key: "ANTHROPIC_API_KEY"
  google_api_key: "GOOGLE_API_KEY"
  openrouter_api_key: "OPENROUTER_API_KEY"
  ollama_base_url: "OLLAMA_BASE_URL"
  default_backend: "AI_DEFAULT_BACKEND"
  default_model: "AI_DEFAULT_MODEL"
  timeout: "AI_TIMEOUT"
  max_retries: "AI_MAX_RETRIES"
  enable_fallbacks: "AI_ENABLE_FALLBACKS"

# Routing configuration
routing:
  # Cloud model detection patterns
  cloud_model_patterns:
    - "openrouter/"
    - "anthropic/"
    - "openai/"
    - "google/"
    - "gpt-"
    - "claude-"
    - "gemini-"
    - "mistral/"
    - "meta/"
    - "cohere/"
    - "replicate/"
    - "huggingface/"

# Constants configuration - centralized hardcoded values
constants:
  # Network timeouts (in seconds)
  timeouts:
    availability_check: 5          # Quick availability checks
    model_list: 10                 # Model listing operations
    backend_health_check: 3        # Backend health/routing checks
    async_thread_join: 2.0         # Background thread cleanup
    cache_ttl: 30                  # Cache TTL for routing decisions (seconds)

  # File size limits (in bytes)
  file_sizes:
    max_file_size: 10485760        # 10MB in bytes (10 * 1024 * 1024)
    kb_threshold: 1024             # 1KB threshold for display
    mb_threshold: 1048576          # 1MB threshold for display (1024 * 1024)

  # Tool execution bounds
  tool_bounds:
    min_timeout: 1                 # Minimum timeout for tool execution
    max_timeout: 30                # Maximum timeout for tool execution
    default_code_timeout: 30       # Default code execution timeout
    default_web_timeout: 10        # Default web request timeout
    math_max_iterations: 1000      # Maximum math calculation iterations

  # Default URLs and endpoints
  urls:
    ollama_default: "http://localhost:11434"  # Default Ollama base URL

  # Retry and rate limiting
  retries:
    default_max_retries: 3         # Default maximum retry attempts
    default_retry_delay: 1.0       # Default retry delay in seconds
    rate_limit_min_delay: 5.0      # Minimum rate limit delay

# File handling configuration
files:
  # Image MIME type mappings
  mime_types:
    ".jpg": "image/jpeg"
    ".jpeg": "image/jpeg"
    ".png": "image/png"
    ".gif": "image/gif"
    ".webp": "image/webp"
    ".bmp": "image/bmp"

  # File size display thresholds (using constants)
  size_format:
    kb_threshold: 1024             # Reference: constants.file_sizes.kb_threshold
    mb_threshold: 1048576          # Reference: constants.file_sizes.mb_threshold
